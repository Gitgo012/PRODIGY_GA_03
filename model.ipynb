{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95c406b",
   "metadata": {},
   "source": [
    "## This jupyter notebook is all about explaining how to perform text generation using Markov chains using a python library called Markovify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cdb8bd",
   "metadata": {},
   "source": [
    "Install the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0e2365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markovify in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.4)\n",
      "Requirement already satisfied: unidecode in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markovify) (1.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashk\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: spacy in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yashk\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashk\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yashk\\appdata\\roaming\\python\\python310\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\yashk\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (2.32.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kagglehub) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashk\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.12\n"
     ]
    }
   ],
   "source": [
    "!pip install markovify\n",
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!pip install -m spacy download en\n",
    "!pip install kagglehub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe26d96",
   "metadata": {},
   "source": [
    "load the dataset - we will be using the Cornell movie dialogue corpus for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff1344bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the dataset: C:\\Users\\Yashk\\.cache\\kagglehub\\datasets\\Cornell-University\\movie-dialog-corpus\\versions\\1\n",
      "Successfully loaded lines:\n",
      "  lineID characterID movieID character          text\n",
      "0  L1045          u0      m0    BIANCA  They do not!\n",
      "1  L1044          u2      m0   CAMERON   They do to!\n",
      "2   L985          u0      m0    BIANCA    I hope so.\n",
      "3   L984          u2      m0   CAMERON     She okay?\n",
      "4   L925          u0      m0    BIANCA     Let's go.\n",
      "Total lines: 293202\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "path = kagglehub.dataset_download(\"Cornell-University/movie-dialog-corpus\")\n",
    "print(\"Path to the dataset:\", path)\n",
    "lines_path=path+\"\\\\movie_lines.tsv\"\n",
    "lines_df = pd.read_csv(\n",
    "    lines_path,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    encoding=\"ISO-8859-2\",\n",
    "    names=[\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"],\n",
    "    on_bad_lines=\"skip\"  \n",
    ")\n",
    "\n",
    "print(\"Successfully loaded lines:\")\n",
    "print(lines_df.head())\n",
    "print(\"Total lines:\", len(lines_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d260c",
   "metadata": {},
   "source": [
    "let's now reconstruct the full conversations from Cornell movie dialog corpus by combining individual movie lines using Id's stores in movie_conversations.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "line_map = { row['lineID']: row['text'] for idx, row in lines_df.iterrows() }\n",
    "conv_path=path+\"\\\\movie_conversations.tsv\"\n",
    "\n",
    "convs_df = pd.read_csv(conv_path, sep=\"\\t\", header=None,\n",
    "                       names=[\"char1\", \"char2\", \"movieID\", \"utteranceIDs\"],\n",
    "                       encoding=\"ISO-8859-2\", on_bad_lines=\"skip\")\n",
    "\n",
    "def parse_conversation(utterance_str):\n",
    "    fixed = re.sub(r\"' '\", \"', '\", utterance_str)\n",
    "    try:\n",
    "        ids = eval(fixed)\n",
    "        return \" \".join([line_map.get(i, \"\") for i in ids])\n",
    "    except:\n",
    "        return \"\"  \n",
    "\n",
    "conversation_texts = convs_df[\"utteranceIDs\"].apply(parse_conversation)\n",
    "conversation_texts = conversation_texts[conversation_texts.str.strip().str.len() > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d523df",
   "metadata": {},
   "source": [
    "let's generate a sample of 5 conversations that we have combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8b73542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample generated sentences:\n",
      "Sentence 1: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. Well I thought we'd start with pronunciation if that's okay with you. Not the hacking and gagging and spitting part.  Please. Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "Sentence 2: You're asking me out.  That's so cute. What's your name again? Forget it.\n",
      "Sentence 3: No no it's my fault -- we didn't have a proper introduction --- Cameron. The thing is Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. Seems like she could get a date easy enough...\n",
      "Sentence 4: Why? Unsolved mystery.  She used to be really popular when she started high school then it was just like she got sick of it or something. That's a shame.\n",
      "Sentence 5: Gosh if only we could find Kat a boyfriend... Let me see what I can do.\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample generated sentences:\")\n",
    "for i in range(5):\n",
    "    print(f\"Sentence {i+1}: {conversation_texts.iloc[i]}\")\n",
    "\n",
    "#print(conversation_texts.head(5)) can also be used to print the first 5 sentences however it will not be in a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77e030e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample corpus blob:\n",
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. Well I thought we'd start with pronunciation if that's okay with you. Not the hacking and gagging and spitting part.  Please. Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "You're asking me out.  That's so cute. What's your name again? Forget it.\n",
      "No no it's my fault -- we didn't have a proper introduction --- Cameron. The thing is Camero\n"
     ]
    }
   ],
   "source": [
    "corpus_blob = \"\\n\".join(conversation_texts.tolist())\n",
    "print(\"Sample corpus blob:\")\n",
    "print(corpus_blob[:500]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee1a18",
   "metadata": {},
   "source": [
    "let's try building a markov model for this combined data through which we will try to predict the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fea24558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "markov_model=markovify.Text(corpus_blob, state_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282b3c4",
   "metadata": {},
   "source": [
    "let's try the model by generating sentences from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12ca5e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example lines generated by the model:\n",
      "Sentence 1: Reality pulled out of Boston.\n",
      "Sentence 2: No time for you to a life clock ticking for him anymore.\n",
      "Sentence 3: It's like some tea.\n",
      "Sentence 4: They extract it from getting so... attached to God?\n",
      "Sentence 5: I left them a few years on earth am I going to go to high school!\n"
     ]
    }
   ],
   "source": [
    "print(\"Example lines generated by the model:\")\n",
    "for i in range(5):\n",
    "    sentence=markov_model.make_sentence()\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d118008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import json\n",
    "\n",
    "# Assuming your model is called `markov_model`\n",
    "with open(\"markov_model.json\", \"w\") as f:\n",
    "    f.write(markov_model.to_json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
